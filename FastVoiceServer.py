from fastapi import FastAPI
from pydantic import BaseModel
from kokoro import KPipeline  # Kokoro TTS æ¨ç†åº“
import numpy as np
import wave
import io
import base64
import os
from contextlib import asynccontextmanager
import logging

import SystemConfig

logger = logging.getLogger(__name__)

os.environ["CUDA_LAUNCH_BLOCKING"] = "1"

@asynccontextmanager
async def lifespan(app: FastAPI):
    # âœ… å¯åŠ¨å‰æ‰§è¡Œ
    logger.info("FastAPI å¯åŠ¨ï¼šis_use_gpu: %s", SystemConfig.is_use_gpu)
    logger.info("FastAPI å¯åŠ¨ï¼šis_dev_mode: %s", SystemConfig.is_dev_mode)

    yield  # ğŸŸ¢ åº”ç”¨è¿è¡Œä¸­

    # âœ… å…³é—­å‰æ‰§è¡Œï¼ˆå¯é€‰ï¼‰
    logger.info("FastAPI å³å°†å…³é—­")
app = FastAPI(lifespan=lifespan)



# å®šä¹‰è¯·æ±‚æ•°æ®æ¨¡å‹
class TTSRequest(BaseModel):
    text: str
    voice_id: str


@app.post("/synthesize")
async def synthesize_speech(req: TTSRequest):
    # 1. æ ¹æ® voice_id é€‰æ‹©å¯¹åº”çš„ Kokoro å£°éŸ³æ¨¡å‹
    voice_choice = req.voice_id.lower()
    if voice_choice == "male":
        selected_voice = "am_michael"  # é»˜è®¤é€‰ç”¨ä¸€ä¸ªç”·å£°éŸ³è‰²
    elif voice_choice == "female":
        selected_voice = "af_heart"  # é»˜è®¤é€‰ç”¨ä¸€ä¸ªå¥³å£°éŸ³è‰²
    else:
        selected_voice = voice_choice  # å¦‚æœæŒ‡å®šäº†å…·ä½“å£°éŸ³IDï¼Œåˆ™ç›´æ¥ä½¿ç”¨

    # ä» voice_id å‰ç¼€ç¡®å®šè¯­è¨€ä»£ç ï¼Œå¦‚ 'a' è¡¨ç¤ºç¾å¼è‹±è¯­
    lang_code = selected_voice[0]
    # åˆå§‹åŒ– Kokoro æ¨ç†ç®¡çº¿ï¼ˆåŠ è½½ç›¸åº”è¯­è¨€çš„æ¨¡å‹ï¼‰
    pipeline = KPipeline(lang_code=lang_code)

    # 2. åˆ©ç”¨ Kokoro æ¨¡å‹åˆæˆè¯­éŸ³
    audio_segments = []
    for _, _, audio in pipeline(req.text, voice=selected_voice):
        # pipeline è¿”å›ç”Ÿæˆçš„éŸ³é¢‘æ®µï¼Œå¯é€æ®µå¤„ç†
        audio_segments.append(np.array(audio))
    # å°†æ‰€æœ‰éŸ³é¢‘æ®µæ‹¼æ¥ä¸ºä¸€ä¸ªå®Œæ•´çš„éŸ³é¢‘åºåˆ—
    audio_data = np.concatenate(audio_segments)

    # 3. è‹¥éœ€è¦ï¼Œè½¬æ¢éŸ³é¢‘é‡‡æ ·ç‡ä¸º16kHz ï¼ˆæ¨¡å‹è¾“å‡ºé»˜è®¤ä¸º24kHzï¼‰
    orig_sr = 24000  # Kokoro é»˜è®¤è¾“å‡ºé‡‡æ ·ç‡
    target_sr = 16000
    if orig_sr != target_sr:
        # ç®€å•çº¿æ€§æ’å€¼è¿›è¡Œä¸‹é‡‡æ ·è½¬æ¢
        old_indices = np.arange(len(audio_data))
        new_length = int(len(audio_data) * target_sr / orig_sr)
        new_indices = np.linspace(0, len(audio_data) - 1, new_length)
        audio_data = np.interp(new_indices, old_indices, audio_data)

    # 4. å°†æµ®ç‚¹éŸ³é¢‘æ•°æ®è½¬æ¢ä¸ºPCM 16ä½æ•´æ•°å¹¶æ‰“åŒ…ä¸ºWAVæ ¼å¼
    audio_int16 = (audio_data * 32767).astype(np.int16)  # å°† -1~1 èŒƒå›´è½¬æ¢ä¸º16ä½æ•´å‹
    buffer = io.BytesIO()
    with wave.open(buffer, 'wb') as wav_file:
        wav_file.setnchannels(1)  # å•å£°é“
        wav_file.setsampwidth(2)  # 16ä½é‡‡æ ·æ·±åº¦ = 2å­—èŠ‚
        wav_file.setframerate(target_sr)  # 16kHz é‡‡æ ·ç‡
        wav_file.writeframes(audio_int16.tobytes())
    wav_bytes = buffer.getvalue()

    # æµ‹è¯•ä½¿ç”¨
    with open("output.wav", "wb") as f:
        f.write(wav_bytes)

    # 5. å°†WAVå­—èŠ‚æ•°æ®ç¼–ç ä¸º base64 å­—ç¬¦ä¸²ï¼Œå¹¶ä½œä¸ºJSONè¿”å›
    audio_base64 = base64.b64encode(wav_bytes).decode('utf-8')
    return {"audio": audio_base64}

if __name__ == "__main__":
    import uvicorn

    if SystemConfig.is_dev_mode:
        uvicorn.run(
            "FastVoiceServer:app",
            host="0.0.0.0",
            port=8189,
            reload=SystemConfig.is_dev_mode,
            log_config="log_config.yml"
        )
    else:
        uvicorn.run(
            app,
            host="0.0.0.0",
            port=8189,
            reload=SystemConfig.is_dev_mode,
            log_config="log_config.yml"
        )